{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilateral Segmentation Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                 dilation=1, groups=1, relu6=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias=False)\n",
    "        self.bn = norm_layer(out_channels)\n",
    "        self.relu = nn.ReLU6(True) if relu6 else nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=nn.BatchNorm2d):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size= 3, stride= stride, padding= 1, bias= False)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(inplanes, planes, kernel_size= 3, stride= stride, padding= 1, bias= False)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialPath(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(SpatialPath, self).__init__()\n",
    "        channels_intermediate= 64\n",
    "        \n",
    "        self.conv_7x7_layer= ConvBNRelu(channels_in, channels_intermediate, 7, 2, 3, norm_layer= nn.BatchNorm2d)\n",
    "        self.conv_3x3_1_layer= ConvBNRelu(channels_intermediate, channels_intermediate, 3, 2, 1, norm_layer= nn.BatchNorm2d)\n",
    "        self.conv_3x3_2_layer= ConvBNRelu(channels_intermediate, channels_intermediate, 3, 2, 1, norm_layer= nn.BatchNorm2d)\n",
    "        self.conv_1x1_layer= ConvBNRelu(channels_intermediate, channels_out, 1, 1, 0, norm_layer= nn.BatchNorm2d)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x= self.conv_7x7_layer(x)\n",
    "        x= self.conv_3x3_1_layer(x)\n",
    "        x= self.conv_3x3_2_layer(x)\n",
    "        x= self.conv_1x1_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureFusionModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels_in, channels_out, reduction= 1, norm_layer= nn.BatchNorm2d):\n",
    "        super(FeatureFusionModule, self).__init__()\n",
    "        self.conv1x1= ConvBNRelu(channels_in, channels_out, 1, 1, 0, norm_layer= norm_layer)\n",
    "        \n",
    "        self.channel_attention= nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            ConvBNRelu(channels_out, channels_out // reduction, 1, 1, 0, norm_layer= norm_layer),\n",
    "            ConvBNRelu(channels_out // reduction, channels_out, 1, 1, 0, norm_layer= norm_layer),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        fusion= torch.cat([x1, x2], dim= 1)\n",
    "        out= self.conv1x1(fusion)\n",
    "        attention= channel_attention(out)\n",
    "        out+= out*attention\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPooling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, norm_layer):\n",
    "        super(GlobalAvgPooling, self).__init__()\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            norm_layer(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.size()[2:]\n",
    "        pool = self.gap(x)\n",
    "        out = F.interpolate(pool, size, mode='bilinear', align_corners=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionRefineModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, norm_layer=nn.BatchNorm2d):\n",
    "        super(AttentionRefineModule, self).__init__()\n",
    "        self.conv3x3 = ConvBNRelu(in_channels, out_channels, 3, 1, 1, norm_layer=norm_layer)\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            ConvBNRelu(out_channels, out_channels, 1, 1, 0, norm_layer=norm_layer),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv3x3(x)\n",
    "        attention = self.channel_attention(x)\n",
    "        x = x * attention\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextPath(nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone= 'resnet18', norm_layer= nn.BatchNorm2d):\n",
    "        super(ContextPath, self).__init__()\n",
    "        \n",
    "        self.conv1= nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias= False)\n",
    "        self.bn1= nn.BatchNorm2d(64)\n",
    "        self.relu= nn.ReLU(inplace= True)\n",
    "        self.maxpool= nn.MaxPool2d(kernel_size= 3, stride= 2, padding= 1)\n",
    "        \n",
    "        layers= [2, 2, 2, 2]\n",
    "        self.layer1= self.conv_layer(BasicBlock, 64, layers[0], norm_layer= norm_layer)\n",
    "        self.layer2= self.conv_layer(BasicBlock, 128, layers[1], norm_layer= norm_layer)\n",
    "        self.layer3= self.conv_layer(BasicBlock, 256, layers[2], norm_layer= norm_layer)\n",
    "        self.layer4= self.conv_layer(BasicBlock, 512, layers[3], norm_layer= norm_layer)\n",
    "\n",
    "        channels_intermediate= 128\n",
    "        self.global_context= GlobalAvgPooling(512, channels_intermediate, norm_layer= norm_layer)\n",
    "        self.arms= nn.ModuleList(\n",
    "            [\n",
    "                AttentionRefineModule(512, channels_intermediate, norm_layer),\n",
    "                AttentionRefineModule(256, channels_intermediate, norm_layer)\n",
    "            ]\n",
    "        )\n",
    "        self.refines= nn.ModuleList(\n",
    "            [\n",
    "                ConvBNRelu(channels_intermediate, channels_intermediate, 3, 1, 1, norm_layer= norm_layer),\n",
    "                ConvBNRelu(channels_intermediate, channels_intermediate, 3, 1, 1, norm_layer= norm_layer)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def conv_layer(self, block, planes, blocks, stride= 1, norm_layer= nn.BatchNorm2d):\n",
    "        downsample= None\n",
    "        if stride != 1 or 64 != planes*block.expansion:\n",
    "            downsample= nn.Sequential(\n",
    "                nn.Conv2d(64, planes*block.expansion, kernel_size= 1, stride= stride, bias= False),\n",
    "                nn.BatchNorm2d(planes*block.expansion)\n",
    "            )\n",
    "            \n",
    "        layers= []\n",
    "        layers.append(block(64, planes, stride, downsample))\n",
    "        inplanes= planes*block.expansion\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        context_blocks = []\n",
    "        context_blocks.append(x)\n",
    "        x = self.layer2(x)\n",
    "        context_blocks.append(x)\n",
    "        c3 = self.layer3(x)\n",
    "        context_blocks.append(c3)\n",
    "        c4 = self.layer4(c3)\n",
    "        context_blocks.append(c4)\n",
    "        context_blocks.reverse()\n",
    "\n",
    "        global_context = self.global_context(c4)\n",
    "        last_feature = global_context\n",
    "        context_outputs = []\n",
    "        for i, (feature, arm, refine) in enumerate(zip(context_blocks[:2], self.arms, self.refines)):\n",
    "            feature = arm(feature)\n",
    "            feature += last_feature\n",
    "            last_feature = F.interpolate(feature, size=context_blocks[i + 1].size()[2:], mode='bilinear', align_corners=True)\n",
    "            last_feature = refine(last_feature)\n",
    "            context_outputs.append(last_feature)\n",
    "\n",
    "        return context_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSNHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels_in, channels_intermediate, num_classes, norm_layer= nn.BatchNorm2d):\n",
    "        super(BSNHead, self).__init__()\n",
    "        self.block= nn.Sequential(\n",
    "            ConvBNRelu(channels_in, channels_intermediate, 3, 1, 1, norm_layer= norm_layer),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(channels_intermediate, num_classes, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x= self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilateralSegmentationNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, backbone= 'resnet18'):\n",
    "        \n",
    "        super(BilateralSegmentationNetwork, self).__init__()\n",
    "        \n",
    "        self.spatial_path= SpatialPath(3, 128)\n",
    "        self.context_path= ContextPath(backbone)\n",
    "        self.ffm= FeatureFusionModule(256, 256, 4)\n",
    "        self.head= BSNHead(256, 64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        size = x.size()[2:]\n",
    "        spatial_out = self.spatial_path(x)\n",
    "        context_out = self.context_path(x)\n",
    "        fusion_out = self.ffm(spatial_out, context_out[-1])\n",
    "        outputs = []\n",
    "        x = self.head(fusion_out)\n",
    "        x = F.interpolate(x, size, mode='bilinear', align_corners=True)\n",
    "        outputs.append(x)\n",
    "        return tuple(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import numpy as np\n",
    "import glob, random\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images, masks, num_classes):\n",
    "        \n",
    "        images_list= glob.glob(images+'/*.png')\n",
    "        masks_list= glob.glob(masks+'/*.png')\n",
    "        self.images= images_list\n",
    "        self.masks= masks_list\n",
    "        \n",
    "        self.base_size= 520\n",
    "        self.crop_size= 480\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img= Image.open(self.images[index]).convert('RGB')\n",
    "        mask= Image.open(self.masks[index])\n",
    "        img, mask= self.transform(img, mask)\n",
    "        print(img.shape, mask.shape)\n",
    "        return img, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def transform(self, img, mask):\n",
    "        # random mirror\n",
    "        if random.random() < 0.5:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "        crop_size = self.crop_size\n",
    "        # random scale (short edge)\n",
    "        short_size = random.randint(int(self.base_size * 0.5), int(self.base_size * 2.0))\n",
    "        w, h = img.size\n",
    "        if h > w:\n",
    "            ow = short_size\n",
    "            oh = int(1.0 * h * ow / w)\n",
    "        else:\n",
    "            oh = short_size\n",
    "            ow = int(1.0 * w * oh / h)\n",
    "        img = img.resize((ow, oh), Image.BILINEAR)\n",
    "        mask = mask.resize((ow, oh), Image.NEAREST)\n",
    "        # pad crop\n",
    "        if short_size < crop_size:\n",
    "            padh = crop_size - oh if oh < crop_size else 0\n",
    "            padw = crop_size - ow if ow < crop_size else 0\n",
    "            img = ImageOps.expand(img, border=(0, 0, padw, padh), fill=0)\n",
    "            mask = ImageOps.expand(mask, border=(0, 0, padw, padh), fill=0)\n",
    "        # random crop crop_size\n",
    "        w, h = img.size\n",
    "        x1 = random.randint(0, w - crop_size)\n",
    "        y1 = random.randint(0, h - crop_size)\n",
    "        img = img.crop((x1, y1, x1 + crop_size, y1 + crop_size))\n",
    "        mask = mask.crop((x1, y1, x1 + crop_size, y1 + crop_size))\n",
    "        # gaussian blur as in PSP\n",
    "        if random.random() < 0.5:\n",
    "            img = img.filter(ImageFilter.GaussianBlur(radius=random.random()))\n",
    "        # final transform\n",
    "        img, mask = np.array(img), np.array(mask)\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class MixSoftmaxCrossEntropyLoss(nn.CrossEntropyLoss):\n",
    "    def init(self, aux=True, aux_weight=0.2, ignore_index=-1, **kwargs):\n",
    "        super(MixSoftmaxCrossEntropyLoss, self).init(ignore_index=ignore_index)\n",
    "        self.aux = aux\n",
    "        self.aux_weight = aux_weight\n",
    "\n",
    "    def _aux_forward(self, *inputs, **kwargs):\n",
    "        *preds, target = tuple(inputs)\n",
    "\n",
    "        loss = super(MixSoftmaxCrossEntropyLoss, self).forward(preds[0], target)\n",
    "        for i in range(1, len(preds)):\n",
    "            aux_loss = super(MixSoftmaxCrossEntropyLoss, self).forward(preds[i], target)\n",
    "            loss += self.aux_weight * aux_loss\n",
    "        return loss\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        preds, target = tuple(inputs)\n",
    "        inputs = tuple(list(preds) + [target])\n",
    "        if self.aux:\n",
    "            return dict(loss=self._aux_forward(*inputs))\n",
    "        else:\n",
    "            return dict(loss=super(MixSoftmaxCrossEntropyLoss, self).forward(*inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRScheduler(object):\n",
    "    r\"\"\"Learning Rate Scheduler\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mode : str\n",
    "        Modes for learning rate scheduler.\n",
    "        Currently it supports 'constant', 'step', 'linear', 'poly' and 'cosine'.\n",
    "    base_lr : float\n",
    "        Base learning rate, i.e. the starting learning rate.\n",
    "    target_lr : float\n",
    "        Target learning rate, i.e. the ending learning rate.\n",
    "        With constant mode target_lr is ignored.\n",
    "    niters : int\n",
    "        Number of iterations to be scheduled.\n",
    "    nepochs : int\n",
    "        Number of epochs to be scheduled.\n",
    "    iters_per_epoch : int\n",
    "        Number of iterations in each epoch.\n",
    "    offset : int\n",
    "        Number of iterations before this scheduler.\n",
    "    power : float\n",
    "        Power parameter of poly scheduler.\n",
    "    step_iter : list\n",
    "        A list of iterations to decay the learning rate.\n",
    "    step_epoch : list\n",
    "        A list of epochs to decay the learning rate.\n",
    "    step_factor : float\n",
    "        Learning rate decay factor.\n",
    "    \"\"\"\n",
    "\n",
    "    def init(self, mode, base_lr=0.01, target_lr=0, niters=0, nepochs=0, iters_per_epoch=0,\n",
    "                 offset=0, power=0.9, step_iter=None, step_epoch=None, step_factor=0.1, warmup_epochs=0):\n",
    "        super(LRScheduler, self).init()\n",
    "        assert (mode in ['constant', 'step', 'linear', 'poly', 'cosine'])\n",
    "\n",
    "        if mode == 'step':\n",
    "            assert (step_iter is not None or step_epoch is not None)\n",
    "        self.niters = niters\n",
    "        self.step = step_iter\n",
    "        epoch_iters = nepochs * iters_per_epoch\n",
    "        if epoch_iters > 0:\n",
    "            self.niters = epoch_iters\n",
    "            if step_epoch is not None:\n",
    "                self.step = [s * iters_per_epoch for s in step_epoch]\n",
    "\n",
    "        self.step_factor = step_factor\n",
    "        self.base_lr = base_lr\n",
    "        self.target_lr = base_lr if mode == 'constant' else target_lr\n",
    "        self.offset = offset\n",
    "        self.power = power\n",
    "        self.warmup_iters = warmup_epochs * iters_per_epoch\n",
    "        self.mode = mode\n",
    "\n",
    "    def call(self, optimizer, num_update):\n",
    "        self.update(num_update)\n",
    "        assert self.learning_rate >= 0\n",
    "        self._adjust_learning_rate(optimizer, self.learning_rate)\n",
    "\n",
    "    def update(self, num_update):\n",
    "        N = self.niters - 1\n",
    "        T = num_update - self.offset\n",
    "        T = min(max(0, T), N)\n",
    "\n",
    "        if self.mode == 'constant':\n",
    "            factor = 0\n",
    "        elif self.mode == 'linear':\n",
    "            factor = 1 - T / N\n",
    "        elif self.mode == 'poly':\n",
    "            factor = pow(1 - T / N, self.power)\n",
    "        elif self.mode == 'cosine':\n",
    "            factor = (1 + math.cos(math.pi * T / N)) / 2\n",
    "        elif self.mode == 'step':\n",
    "            if self.step is not None:\n",
    "                count = sum([1 for s in self.step if s <= T])\n",
    "                factor = pow(self.step_factor, count)\n",
    "            else:\n",
    "                factor = 1\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # warm up lr schedule\n",
    "        if self.warmup_iters > 0 and T < self.warmup_iters:\n",
    "            factor = factor * 1.0 * T / self.warmup_iters\n",
    "\n",
    "        if self.mode == 'step':\n",
    "            self.learning_rate = self.base_lr * factor\n",
    "        else:\n",
    "            self.learning_rate = self.target_lr + (self.base_lr - self.target_lr) * factor\n",
    "\n",
    "    def _adjust_learning_rate(self, optimizer, lr):\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        # enlarge the lr at the head\n",
    "        for i in range(1, len(optimizer.param_groups)):\n",
    "            optimizer.param_groups[i]['lr'] = lr * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupPolyLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, target_lr=0, max_iters=0, power=0.9, warmup_factor=1.0 / 3,\n",
    "                 warmup_iters=500, warmup_method='linear', last_epoch=-1):\n",
    "        if warmup_method not in (\"constant\", \"linear\"):\n",
    "            raise ValueError(\n",
    "                \"Only 'constant' or 'linear' warmup_method accepted \"\n",
    "                \"got {}\".format(warmup_method))\n",
    "\n",
    "        self.target_lr = target_lr\n",
    "        self.max_iters = max_iters\n",
    "        self.power = power\n",
    "        self.warmup_factor = warmup_factor\n",
    "        self.warmup_iters = warmup_iters\n",
    "        self.warmup_method = warmup_method\n",
    "\n",
    "        super(WarmupPolyLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        N = self.max_iters - self.warmup_iters\n",
    "        T = self.last_epoch - self.warmup_iters\n",
    "        if self.last_epoch < self.warmup_iters:\n",
    "            if self.warmup_method == 'constant':\n",
    "                warmup_factor = self.warmup_factor\n",
    "            elif self.warmup_method == 'linear':\n",
    "                alpha = float(self.last_epoch) / self.warmup_iters\n",
    "                warmup_factor = self.warmup_factor * (1 - alpha) + alpha\n",
    "            else:\n",
    "                raise ValueError(\"Unknown warmup type.\")\n",
    "            return [self.target_lr + (base_lr - self.target_lr) * warmup_factor for base_lr in self.base_lrs]\n",
    "        factor = pow(1 - T / N, self.power)\n",
    "        return [self.target_lr + (base_lr - self.target_lr) * factor for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from score import SegmentationMetric\n",
    "\n",
    "class NetworkTrainer(object):\n",
    "    \n",
    "    def __init__(self, gpus, device, learning_rate, num_classes, batch_size):\n",
    "        self.device= torch.device(device)\n",
    "        \n",
    "        train_dataset= MyDataset('E:\\\\pytorch\\\\bisenet\\\\dataset\\\\images', 'E:\\\\pytorch\\\\bisenet\\\\dataset\\\\masks', num_classes)\n",
    "        iterations= len(train_dataset) // (num_gpus*batch_size)\n",
    "        \n",
    "        self.train_loader= data.DataLoader(dataset= train_dataset, num_workers=0, pin_memory=True)\n",
    "        self.model= BilateralSegmentationNetwork(num_classes=3, backbone='resnet18')\n",
    "        self.criterion= MixSoftmaxCrossEntropyLoss()\n",
    "        self.optimizer= torch.optim.Adam(self.model.parameters(), lr= learning_rate)\n",
    "        self.lr_scheduler= WarmupPolyLR(self.optimizer, power= 0.9)\n",
    "        self.metric= SegmentationMetric(num_classes)\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        for iteration, (images, masks) in enumerate(self.train_loader):\n",
    "            iteration+= 1\n",
    "            self.lr_scheduler.step()\n",
    "            \n",
    "            images= images.to(self.device)\n",
    "            masks= masks.to(self.device)\n",
    "            print(images.shape)\n",
    "            outputs= self.model(images)\n",
    "            loss_dict= self.criterion(outputs, masks)\n",
    "            losses= sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            print('iteration ', iteration, ' over')\n",
    "        \n",
    "        torch.save(model.state_dict(), './weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_gpus= 1\n",
    "    learning_rate= 0.0001\n",
    "    if torch.cuda.is_available():\n",
    "        cudnn.benchmark= True\n",
    "        device= 'cuda'\n",
    "        \n",
    "    learning_rate= learning_rate*num_gpus\n",
    "    batch_size= 4\n",
    "    num_classes= 4\n",
    "    network_trainer= NetworkTrainer(num_gpus, device, learning_rate, num_classes, batch_size)\n",
    "    network_trainer.train()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
